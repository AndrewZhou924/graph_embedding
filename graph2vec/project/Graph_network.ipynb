{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deepctr import SingleFeat\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from model import xDeepFM_MTL\n",
    "import tensorflow as tf\n",
    "from deepctr.input_embedding import preprocess_input_embedding\n",
    "\n",
    "\n",
    "from deepctr.layers.core import MLP, PredictionLayer\n",
    "from deepctr.layers.interaction import CIN\n",
    "from deepctr.layers.utils import concat_fun\n",
    "from deepctr.utils import check_feature_config_dict\n",
    "\n",
    "import json\n",
    "import gc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    del users_info\n",
    "except:\n",
    "    pass\n",
    "with open(\"users.json\",'r') as load_f:\n",
    "    users_info = json.load(load_f)\n",
    "for key in users_info.keys():\n",
    "    users_info[key].pop('unfinish')\n",
    "    users_info[key].pop('dislike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    del items_info\n",
    "except:\n",
    "    pass\n",
    "with open(\"items.json\",'r') as load_f:\n",
    "    items_info = json.load(load_f)\n",
    "for key in items_info.keys():\n",
    "    items_info[key].pop('unfinish')\n",
    "    items_info[key].pop('dislike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./input/final_track2_train.txt', sep='\\t', names=[\n",
    "    'uid', 'user_city', 'item_id', 'author_id', 'item_city', 'channel', 'finish', 'like', 'music_id', 'did', 'creat_time', 'video_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['user_city']\n",
    "del data['author_id']\n",
    "del data['item_city']\n",
    "del data['channel']\n",
    "del data['music_id']\n",
    "del data['did']\n",
    "del data['creat_time']\n",
    "del data['video_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dim = 73973\n",
    "item_dim = 4122688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vec = np.random.random((user_dim,8))\n",
    "item_vec = np.random.random((item_dim,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_input = tf.keras.Input(shape=(1,))\n",
    "item_id_input = tf.keras.Input(shape=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_vec_emb = tf.keras.layers.Embedding(input_dim=(user_dim),output_dim=8,weights = [user_vec])\n",
    "i_vec_emb = tf.keras.layers.Embedding(input_dim=(item_dim),output_dim=8,weights = [item_vec])\n",
    "\n",
    "input_u_vec = tf.keras.layers.Flatten()(u_vec_emb(uid_input))\n",
    "input_i_vec = tf.keras.layers.Flatten()(u_vec_emb(item_id_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 历史上用户交互的item\n",
    "his_like_i = tf.keras.Input(shape=(10,))\n",
    "his_finish_i = tf.keras.Input(shape=(100,))\n",
    "# his_dislike_i = tf.keras.Input(shape=(10,))\n",
    "# his_unfinish_i = tf.keras.Input(shape=(10,))\n",
    "\n",
    "# 历史上看过item的用户\n",
    "his_like_u = tf.keras.Input(shape=(10,))\n",
    "his_finish_u = tf.keras.Input(shape=(100,))\n",
    "# his_dislike_u = tf.keras.Input(shape=(10,))\n",
    "# his_unfinish_u = tf.keras.Input(shape=(10,))\n",
    "\n",
    "#特征 embedding\n",
    "his_like_i_v = i_vec_emb(his_like_i)\n",
    "his_finish_i_v = i_vec_emb(his_finish_i)\n",
    "his_like_u_v = u_vec_emb(his_like_u)\n",
    "his_finish_u_v = u_vec_emb(his_finish_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "his_like_i_feature = tf.keras.layers.LSTM(8, dropout=0.2, recurrent_dropout=0.2)(his_like_i_v)\n",
    "his_finish_i_feature = tf.keras.layers.LSTM(8, dropout=0.2, recurrent_dropout=0.2)(his_finish_i_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "his_like_u_feature = tf.keras.layers.LSTM(8, dropout=0.2, recurrent_dropout=0.2)(his_like_u_v)\n",
    "his_finish_u_feature = tf.keras.layers.LSTM(8, dropout=0.2, recurrent_dropout=0.2)(his_finish_u_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feature = tf.keras.layers.concatenate([input_u_vec,input_i_vec,his_like_i_feature,\n",
    "                                              his_finish_i_feature,his_like_u_feature,his_finish_u_feature],axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = tf.keras.layers.Dense(20,activation='relu')(final_feature)\n",
    "fc2 = tf.keras.layers.Dense(10,activation='relu')(fc1)\n",
    "final_out  = tf.keras.layers.Dense(2,activation='sigmoid')(fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_list = [uid_input,item_id_input,his_like_i,his_finish_i,his_like_u,his_finish_u]\n",
    "model = tf.keras.models.Model(inputs=inputs_list, outputs= [final_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>item_id</th>\n",
       "      <th>finish</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57384</td>\n",
       "      <td>43192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3230</td>\n",
       "      <td>46822</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1249</td>\n",
       "      <td>1209078</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11928</td>\n",
       "      <td>1209079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51266</td>\n",
       "      <td>1209080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid  item_id  finish  like\n",
       "0  57384    43192       0     0\n",
       "1   3230    46822       1     0\n",
       "2   1249  1209078       0     0\n",
       "3  11928  1209079       0     0\n",
       "4  51266  1209080       1     0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_FRAC = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = ['uid',  'item_id']\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "target = ['finish', 'like']\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "sparse_feature_list = [SingleFeat(feat, data[feat].nunique())\n",
    "                       for feat in sparse_features]\n",
    "\n",
    "train_size = int(data.shape[0]*(1-VALIDATION_FRAC))\n",
    "train = data.iloc[:train_size]\n",
    "test = data.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"binary_crossentropy\",metrics=[auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "OK\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (32,10) into shape (32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-168-12fde4f54610>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musers_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitems_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m15697872\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m32\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\郭潇俊\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mc:\\users\\郭潇俊\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    145\u001b[0m       \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\郭潇俊\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    829\u001b[0m       \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\郭潇俊\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\郭潇俊\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m_data_generator_task\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    694\u001b[0m               \u001b[1;31m# => Serialize calls to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m               \u001b[1;31m# infinite iterator/generator's next() function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m               \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-167-6cc93687210c>\u001b[0m in \u001b[0;36mdata_generator\u001b[1;34m(data, users_info, items_info, batch_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0milike\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mget_item_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitems_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mid_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mifinish\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mget_item_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitems_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mid_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mulike\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mufinish\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0milike\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mifinish\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0myy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (32,10) into shape (32)"
     ]
    }
   ],
   "source": [
    "model.fit_generator(data_generator(data,users_info,items_info, batch_size = 32),steps_per_epoch =15697872//32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for a binary classifier\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "#     print(y_true.shape)\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return tf.math.reduce_sum(s, axis=0)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# PFA, prob false alert for binary classifier\n",
    "\n",
    "def binary_PFA(y_true, y_pred, threshold=tf.constant(0.5)):\n",
    "    y_pred = tf.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = tf.math.reduce_sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = tf.math.reduce_sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# P_TA prob true alerts for binary classifier\n",
    "\n",
    "def binary_PTA(y_true, y_pred, threshold=tf.constant(0.5)):\n",
    "    y_pred = tf.cast(y_pred >= threshold, 'float32')\n",
    "    P = tf.math.reduce_sum(y_true)\n",
    "    TP = tf.math.reduce_sum(y_pred * y_true)\n",
    "    return TP/P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_info(iid,items_info):\n",
    "    id_item = items_info.get(str(iid),{})\n",
    "    if id_item == {}:\n",
    "        return -1*np.ones(10),-1*np.ones(100)\n",
    "    lake_length = 10-len(id_item['like'][:10])\n",
    "#     print(lake_length)\n",
    "#     print(id_item['like'][:10])\n",
    "    if lake_length > 1:\n",
    "        id_item['like'].extend([-1  for i in range(lake_length)])\n",
    "#     print(id_item['like'][:10].extend([-1  for i in range(lake_length)]))\n",
    "    like_info =  np.array(id_item['like'][:10])\n",
    "    lake_length = 100-len(id_item['finish'][:100])\n",
    "    if lake_length>1:\n",
    "        id_item['finish'].extend([-1  for i in range(lake_length)])\n",
    "    finish_info = np.array(id_item['finish'][:100])\n",
    "    return like_info,finish_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_1:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_2:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_3:0' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'input_4:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'input_5:0' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'input_6:0' shape=(?, 100) dtype=float32>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_user = users_info.get(str(1),{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finish': [1212837,\n",
       "  815912,\n",
       "  204823,\n",
       "  233072,\n",
       "  1209483,\n",
       "  484515,\n",
       "  1225800,\n",
       "  96460,\n",
       "  1322994,\n",
       "  1209100,\n",
       "  1210360,\n",
       "  119834,\n",
       "  1002773,\n",
       "  66895,\n",
       "  1425948,\n",
       "  1251266,\n",
       "  745173,\n",
       "  82099,\n",
       "  1343956,\n",
       "  592182,\n",
       "  1211573,\n",
       "  1211519,\n",
       "  428554,\n",
       "  126899,\n",
       "  79942,\n",
       "  34237,\n",
       "  2027215,\n",
       "  3366503,\n",
       "  3525299,\n",
       "  3526430,\n",
       "  325628,\n",
       "  3574178,\n",
       "  3527318,\n",
       "  3526204,\n",
       "  3315799,\n",
       "  446497,\n",
       "  4418,\n",
       "  3483623,\n",
       "  960201,\n",
       "  3847358,\n",
       "  25877,\n",
       "  936800,\n",
       "  3846068,\n",
       "  3828363,\n",
       "  3878852,\n",
       "  682822,\n",
       "  3039443,\n",
       "  809730,\n",
       "  16814,\n",
       "  1586462,\n",
       "  862887,\n",
       "  343,\n",
       "  3065616,\n",
       "  11328,\n",
       "  247375,\n",
       "  3846522,\n",
       "  1381311,\n",
       "  3103775,\n",
       "  1196371,\n",
       "  1169296,\n",
       "  1251032,\n",
       "  3847126,\n",
       "  709941,\n",
       "  2460528,\n",
       "  811736,\n",
       "  1344568,\n",
       "  1687435,\n",
       "  858423,\n",
       "  9086,\n",
       "  3239348,\n",
       "  680986,\n",
       "  102018,\n",
       "  53890,\n",
       "  469085,\n",
       "  1048248,\n",
       "  3363060,\n",
       "  59517,\n",
       "  115604,\n",
       "  414505,\n",
       "  6161,\n",
       "  375300,\n",
       "  646550,\n",
       "  286535,\n",
       "  655666,\n",
       "  1705819,\n",
       "  768147,\n",
       "  1047809,\n",
       "  3271924,\n",
       "  3448084,\n",
       "  982633,\n",
       "  3458439,\n",
       "  786612,\n",
       "  84895,\n",
       "  3561,\n",
       "  1,\n",
       "  3237811,\n",
       "  634091,\n",
       "  637139,\n",
       "  682488,\n",
       "  703363,\n",
       "  665573,\n",
       "  780131,\n",
       "  3995,\n",
       "  637599,\n",
       "  645506,\n",
       "  652649,\n",
       "  646335,\n",
       "  49370,\n",
       "  1023455,\n",
       "  70126,\n",
       "  78755,\n",
       "  633500,\n",
       "  93230,\n",
       "  211932,\n",
       "  641069],\n",
       " 'like': [188301, 1607171, 3525750, -1, -1, -1, -1, -1, -1, -1]}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_info(uid,users_info):\n",
    "    id_user = users_info.get(str(uid),{})\n",
    "    if id_user == {}:\n",
    "        return -1*np.ones(10),-1*np.ones(100)\n",
    "    lake_length = 10-len(id_user['like'][:10])\n",
    "#     print(lake_length)\n",
    "#     print(id_user['like'][:10])\n",
    "    if lake_length > 1:\n",
    "        id_user['like'].extend([-1  for i in range(lake_length)])\n",
    "#     print(id_user['like'][:10].extend([-1  for i in range(lake_length)]))\n",
    "    like_info =  np.array(id_user['like'][:10])\n",
    "    lake_length = 100-len(id_user['finish'][:100])\n",
    "    if lake_length>1:\n",
    "        id_user['finish'].extend([-1  for i in range(lake_length)])\n",
    "    finish_info = np.array(id_user['finish'][:100])\n",
    "    return like_info,finish_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data,users_info,items_info, batch_size): \n",
    "    idx = np.arange(data.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    batches = [idx[range(batch_size*i, min(len(data), batch_size*(i+1)))] for i in range(len(data)//batch_size+1)]\n",
    "    uids = data.uid.values\n",
    "    iids = data.item_id.values\n",
    "    finishes = data.finish.values\n",
    "    likes = data.like.values\n",
    "    target = np.transpose(np.vstack((uids,iids)))\n",
    "    print('OK')\n",
    "    while True:\n",
    "        for i in batches:\n",
    "            xu = uids[i]\n",
    "            xi = iids[i]\n",
    "            yf = finishes[i]\n",
    "            yl = likes[i]\n",
    "            ulike = np.array([get_user_info(id_,users_info)[0] for id_ in xu])\n",
    "            ufinish = np.array([get_user_info(id_,users_info)[1] for id_ in xu])\n",
    "            ilike = np.array([get_item_info(id_,items_info)[0] for id_ in xi])\n",
    "            ifinish = np.array([get_item_info(id_,items_info)[1] for id_ in xi])\n",
    "            xx = np.array([xu,xi,ulike,ufinish,ilike,ifinish])\n",
    "            yy = target[i]\n",
    "            yield (xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
